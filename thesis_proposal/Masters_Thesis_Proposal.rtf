{\rtf1\ansi\deff3\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset2 Symbol;}{\f2\fswiss\fprq2\fcharset0 Arial;}{\f3\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f4\froman\fprq0\fcharset128 Times New Roman;}{\f5\froman\fprq0\fcharset128 Arial;}{\f6\froman\fprq2\fcharset128 Times New Roman;}{\f7\fswiss\fprq0\fcharset128 Liberation Sans{\*\falt Arial};}{\f8\fnil\fprq0\fcharset128 Times New Roman;}{\f9\fnil\fprq0\fcharset128 Liberation Serif{\*\falt Times New Roman};}{\f10\fnil\fprq0\fcharset128 FreeSans;}{\f11\fnil\fprq2\fcharset0 FreeSans;}{\f12\fswiss\fprq0\fcharset128 FreeSans;}{\f13\fnil\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}}
{\colortbl;\red0\green0\blue0;\red67\green67\blue67;\red102\green102\blue102;\red0\green0\blue128;\red128\green0\blue0;\red128\green128\blue128;}
{\stylesheet{\s0\snext0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105 Normal;}
{\s1\sbasedon0\snext1\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb400\sa120\keepn\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs40\alang1081\ai0\ab0\loch\f5\fs40\lang4105 Heading 1;}
{\s2\sbasedon0\snext2\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb360\sa120\keepn\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs32\alang1081\ai0\ab0\loch\f5\fs32\lang4105 Heading 2;}
{\s3\sbasedon0\snext3\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb320\sa80\keepn\ltrpar\cf2\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs28\alang1081\ai0\ab0\loch\f5\fs28\lang4105 Heading 3;}
{\s4\sbasedon0\snext4\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb280\sa80\keepn\ltrpar\cf3\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs24\alang1081\ai0\ab0\loch\f5\fs24\lang4105 Heading 4;}
{\s5\sbasedon0\snext5\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb240\sa80\keepn\ltrpar\cf3\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f5\fs22\lang4105 Heading 5;}
{\s6\sbasedon0\snext6\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb240\sa80\keepn\ltrpar\cf3\strike0\expnd-2\expndtw-10\i\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai\ab0\loch\f5\fs22\lang4105 Heading 6;}
{\*\cs15\snext15 Default Paragraph Font;}
{\*\cs16\snext16\cf4\ul\ulc1\langfe255\alang255\lang255 Internet Link;}
{\*\cs17\snext17\cf5\ul\ulc1\langfe255\alang255\lang255 Visited Internet Link;}
{\s18\sbasedon0\snext19\sl480\slmult1\ql\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb240\sa120\keepn\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af10\langfe2052\dbch\af11\afs28\alang1081\ai0\ab0\loch\f7\fs28\lang4105 Heading;}
{\s19\sbasedon0\snext19\sl288\slmult1\ql\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa140\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f5\fs22\lang4105 Text Body;}
{\s20\sbasedon19\snext20\sl288\slmult1\ql\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa140\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af10\langfe2052\dbch\af12\afs22\alang1081\ai0\ab0\loch\f5\fs22\lang4105 List;}
{\s21\sbasedon0\snext21\sl480\slmult1\ql\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb120\sa120\noline\ltrpar\cf1\strike0\expnd-2\expndtw-10\i\ulnone\ulc1\b0\kerning1\dbch\af10\langfe2052\dbch\af12\afs24\alang1081\ai\ab0\loch\f5\fs24\lang4105 Caption;}
{\s22\sbasedon0\snext22\sl480\slmult1\ql\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\noline\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af10\langfe2052\dbch\af12\afs22\alang1081\ai0\ab0\loch\f5\fs22\lang4105 Index;}
{\s23\sbasedon0\snext23\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa60\keepn\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs52\alang1081\ai0\ab0\loch\f5\fs52\lang4105 Title;}
{\s24\sbasedon0\snext24\sl480\slmult1\ql\keep\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa320\keepn\ltrpar\cf3\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs30\alang1081\ai0\ab0\loch\f5\fs30\lang4105 Subtitle;}
{\s25\sbasedon0\snext25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105 Condensed1;}
{\s26\sbasedon0\snext26\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105 Quotations;}
}{\info{\creatim\yr0\mo0\dy0\hr0\min0}{\revtim\yr0\mo0\dy0\hr0\min0}{\printim\yr0\mo0\dy0\hr0\min0}{\comment LibreOffice}{\vern67241986}}\deftab720
\viewscale110
{\*\pgdsctbl
{\pgdsc0\pgdscuse451\pgwsxn12240\pghsxn15840\marglsxn1440\margrsxn1440\margtsxn1440\margbsxn1440\pgdscnxt0 Default Style;}}
\formshade{\*\pgdscno0}\paperh15840\paperw12240\margl1440\margr1440\margt1440\margb1440\sectd\sbknone\sectunlocked1\pgndec\pgwsxn12240\pghsxn15840\marglsxn1440\margrsxn1440\margtsxn1440\margbsxn1440\ftnbj\ftnstart1\ftnrstcont\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnrlc
\pgndec\pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105\qc{\cf1\b\dbch\af8\afs28\alang1025\ab\rtlch \ltrch\loch\fs28\lang1033\loch\f4
Audio Source Separation via the Grouping of Partials in the }
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105\qc{\cf1\b\dbch\af8\afs28\alang1025\ab\rtlch \ltrch\loch\fs28\lang1033\loch\f4
Sum-of-Sinusoids Model}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105\qc{\cf1\b\dbch\af8\afs24\alang1025\ab\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Nicholas Esterer \u8211\'3f M.A. in Music Technology}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
The sparse nature of musical sounds }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
(hereafter referred to as }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
signals}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
) }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
allows for their succinct representation }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
as a mixture of time-varying partials (not necessarily harmonically related). In the signal processing literature this is called the}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
sum-of-sinusoids }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
or }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
additive model }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
and the partials are called }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
sinusoidal components (SC) }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
[1]. This model is convenient for its relative parsimony while keeping common signal transformations pertinent to computer music easy to perform. Operations like time-stretching, transposition, noise-removal and filtering are simple and efficient to perform on the sinusoid model. In theory, the act of separating multiple superimposed sounds\uc2 \u8212\'81\'5caudio source separation\u8212\'81\'5cshould also be simple: the desired \uc1 }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
SC}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 are chosen and the rest discarded. The difficult problem lies in choosing the group of }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
SC}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 that come from the same source. }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
To this end we propose a system that extracts (numerical) descriptions of the SC and at the same time groups them into sources, based on their descriptions.}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\b\dbch\af8\afs24\alang1025\ab\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Theoretical Background and Methodology}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
In recent years techniques estimating the parameters of more descriptive sinusoidal models }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
incorporate}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 instantaneous frequency- and amplitude-modulations (FM and AM) [2]. }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
For tractability, t}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
hese parameters }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
are}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 only computed }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
at a few unique times within a signal}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 and it is assumed the resulting data points represent either noise or underlying SC belonging to a particular source. The data indicating }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
to which source a data point belongs}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 are missing, while we do have some information on the nature of the underlying component }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
(the computed parameters)}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
. }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Expectation Maximization (EM) }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
is a technique applicable in such circumstances [11]: It computes the most highly expected values of the missing data given the available information. It remains to connect the data points together in a plausible way, hopefully resulting in the original component. This can be phrased as an optimization problem: We want to find the optimal set of connections between data points, subject to some constraints (e.g., each data point can only belong to one component, etc.). This type of problem is readily solved as a }{\cf1\i\dbch\af8\afs24\alang1025\ai\rtlch \ltrch\loch\fs24\lang1033\loch\f4
linear program (LP)}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
, a technique finding renewed interest due to promising proofs of its worst-case computational complexity [3]. }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
It has}{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
 been shown that common FM [4] and AM [5] were plausible data with which to group sinusoids common to one source [6], and it is with these data that we will define a measure of optimality.}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\b\dbch\af8\afs24\alang1025\ab\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Objectives}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\b\dbch\af8\afs24\alang1025\ab\rtlch \ltrch\loch\fs24\lang1033\loch\f4
\tab }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
We want to assess the applicability of the above techniques to the source separation problem. Using a set of AM and FM parameters estimated at one time, we will use the Gaussian mixture clustering algorithm (an incarnation of EM) to group parameters into sources [7]. It remains to group parameters across time. While various methods have been proposed for this (e.g., [8], [9]), motivated by its desirable properties outlined above, we will try a new method based on a technique for tracking multiple objects using LP [10]. The result are data indicating the parameter-source classification at one time, and the parameter connections across time, i.e., which parameters belong to which source. From these parameters, the original sources can be synthesized.}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\b\dbch\af8\afs24\alang1025\ab\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Contribution}
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
This thesis demonstrates the mastering of a variety of musical signal processing techniques and their integration into a larger framework in an attempt to solve the difficult problem of audio source separation on a single channel. }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
Previous work on this problem either required the SC to be harmonically related [12], or that their AM and FM be small (e.g., [13]). Neither are the case in our proposed method. }{\cf1\dbch\af8\afs24\alang1025\rtlch \ltrch\loch\fs24\lang1033\loch\f4
While documenting the knowledge gained throughout the Master\uc2 \u8217\'81\'66s program, the contribution is furthermore applicable to the domains of audio editing (e.g., unwanted sources can be discarded, effects can be applied to a single source, etc.) and analysis (e.g., measurements can be made for only particular sources). \uc1 }
\par \pard\plain \s0\sl480\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar{\*\hyphen2\hyphlead2\hyphtrail2\hyphmax0}\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs22\lang4105\afs24\rtlch \ltrch\loch\fs24

\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105\rtlch \ltrch\loch

\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\b\dbch\af8\alang1025\ab\rtlch \ltrch\loch\lang1033\loch\f4
Bibliography}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[1] Serra, Xavier, and Julius Smith. "Spectral modeling synthesis: A sound analysis/synthesis system based on a deterministic plus stochastic decomposition." }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Computer Music Journal}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
 14, no. 4 (1990): 12-24.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[2] Hamilton, Brian, Philippe Depalle, and Sylvain Marchand. "Theoretical and practical comparisons of the reassignment method and the derivative method for the estimation of the frequency slope." In }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Applications of Signal Processing to Audio and Acoustics, 2009. WASPAA'09. IEEE Workshop on}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
, pp. 345-348. IEEE, 2009.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[3] Boyd, Stephen, and Lieven Vandenberghe. }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Convex optimization}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
. Cambridge university press, 2004.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[4] McAdams, Stephen. "Segregation of concurrent sounds. I: Effects of frequency modulation coherence." }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
The Journal of the Acoustical Society of America}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
 86, no. 6 (1989): 2148-2159.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[5] Li, Yipeng, John Woodruff, and DeLiang Wang. "Monaural musical sound separation based on pitch and common amplitude modulation." }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Audio, Speech, and Language Processing, IEEE Transactions on}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
 17, no. 7 (2009): 1361-1371.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[6] Creager, Elliot. \uc2 \u8220\'81\'67Musical source separation by coherent frequency modulation cues.\u8221\'81\'68 2016. Masters Thesis, McGill University. Accessed April 18, 2016. \uc1 }{\cf1\dbch\af8\langfe255\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
http}{\cf1\rtlch \ltrch\loch\loch\f4
://digitool.library.mcgill.ca/thesisfile139201.pdf.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[7] Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
The elements of statistical learning}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
. Vol. 1. Springer, Berlin: Springer series in statistics, 2001.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[8] }{\cf1\rtlch \ltrch\loch\loch\f4
McAulay, Robert J., and Thomas F. Quatieri. "Speech analysis/synthesis based on a sinusoidal representation." }{\cf1\i\rtlch \ltrch\loch\loch\f4
Acoustics, Speech and Signal Processing, IEEE Transactions on}{\cf1\rtlch \ltrch\loch\loch\f4
 34, no. 4 (1986): 744-754.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\rtlch \ltrch\loch\loch\f4
[9] Depalle, Ph, Guillermo Garcia, and Xavier Rodet. "Tracking of partials for additive sound synthesis using hidden Markov models." In }{\cf1\i\rtlch \ltrch\loch\loch\f4
Acoustics, Speech, and Signal Processing, 1993. ICASSP-93., 1993 IEEE International Conference on}{\cf1\rtlch \ltrch\loch\loch\f4
, vol. 1, pp. 225-228. IEEE, 1993.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[10] Jiang, Hao, Sidney Fels, and James J. Little. "A linear programming approach for multiple object tracking." In }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
, pp. 1-8. IEEE, 2007.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
[11] Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. "Maximum likelihood from incomplete data via the EM algorithm." }{\cf1\i\dbch\af8\alang1025\ai\rtlch \ltrch\loch\lang1033\loch\f4
Journal of the royal statistical society. Series B (methodological)}{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033\loch\f4
 (1977): 1-38.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033
[12] }{\rtlch \ltrch\loch
Wang, Avery Li-Chun. "Instantaneous and frequency-warped signal processing techniques for auditory source separation." PhD diss., }{\rtlch \ltrch\loch
S}{\rtlch \ltrch\loch
tanford }{\rtlch \ltrch\loch
U}{\rtlch \ltrch\loch
niversity, 1994.}
\par \pard\plain \s25\sl336\slmult1\qj\widctlpar\faauto\li0\ri0\lin0\rin0\fi0\sb0\sa0\ltrpar\cf1\strike0\expnd-2\expndtw-10\i0\ulnone\ulc1\b0\kerning1\dbch\af9\langfe2052\dbch\af13\afs22\alang1081\ai0\ab0\loch\f6\fs24\lang4105{\cf1\dbch\af8\alang1025\rtlch \ltrch\loch\lang1033
[13] }{\rtlch \ltrch\loch
Vincent, Emmanuel, Nancy Bertin, and Roland Badeau. "Harmonic and inharmonic nonnegative matrix factorization for polyphonic pitch transcription." In }{\i\rtlch \ltrch\loch
Acoustics, Speech and Signal Processing, 2008. ICASSP 2008. IEEE International Conference on}{\rtlch \ltrch\loch
, pp. 109-112. IEEE, 2008.}
\par }