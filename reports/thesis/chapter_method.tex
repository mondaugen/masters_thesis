\chapter{Methodology\label{chap:method}}

Most audio source separation strategies use some combination of two general
methodologies: at one end of this continuum are those that use physical or
structural models of the sources and at the other, those that use purely
statistical models. Here we give a brief overview of some previously proposed
techniques.

\section{Additive sinusoidal model}

The additive sinusoidal model \cite{serra1989system}, \cite{mcaulay1986speech},
is a convenient model with wide-spread use in the computer music community.
Various authors have applied this model to the source separation problem. For
example, in \cite{virtanen2003algorithm} a prior estimation of the fundamental
frequencies is used in tandem with temporal and spectral smoothness constraints
to separate sources estimated via an additive model. Similar to this thesis,
\cite{creager2016musicalsource} uses an additive sinusoidal model to provide
frequency-modulation cues to a latent component technique, and in
\cite{li2009monaural}, common amplitude-modulation and fundamental frequency
estimation are use to separate sources, the additive sinusoidal model being used
to reconstruct the phases of overlapping harmonics using the fundamental
frequencies. The additive sinusoidal model is also the model adopted in this
thesis, its use justified in Chapter~\ref{chap:sigmod}.

\section{Multiple fundamental frequency estimation}

This technique assumes the signal considered can be described in a format akin
to the musical score --- a collection of notes each with times indexing their
beginning and end and a frequency, the fundamental, describing the perceived
pitch of the note. Multiple fundamental frequency estimation for the purposes of music
transcription dates back to the 1970s \cite[ch.~20]{havelock2008handbook}
\cite{moorer1977transcription}. This
is related to audio source separation because the resulting high-level
representation --- the estimated score --- can be used to synthesize signals
corresponding to subsets of
notes in the score, e.g., if a particular instrument is desired, its notes are
extracted and then a signal is synthesized using stored recordings of the
instrument or instrument-modeling synthesis techniques. The technique has become
quite developed, see \cite[ch.~20]{havelock2008handbook} for a review of
modern techniques.

There are some drawbacks to the technique. Many musical signals of interest such
as unpitched percussion, do not always have a perceiveable fundamental
frequency. A musical score describes notes as having distinct boundaries in time
and frequency, which is not always true when one considers
musical gestures such as portamento or \textit{dal niente}\footnote{``Out of
    nothing'': usually accompanying a crescendo and indicating that the player
start from silence and gradually increase their playing dynamic.}. Nevertheless,
the production of even a crude score from a musical signals is useful in
applications such as automated music transcription (e.g.,
\cite{ryynanen2008automatic}) or music catalogue query
\cite{mcnab1996towards}.

\section{Principal latent component analysis (PLCA) and non-negative matrix
factorizations (NMF)}

\subsection{Motivation}

The power spectrum of a signal and consequently its spectrogram are always
non-negative valued. If a signal is considered as consisting of a sum of
original source signals, these source signals will have non-negative
spectrograms as well. The following two techniques attempt to determine these
spectrograms solely from a spectrogram of their mixture using techniques for
determining latent variables. We will refer to techniques of this sort as
\textit{latent variable models}. The technique is discussed in a bit more detail
in the following to demonstrate how it differs from the additive technique
explored in this thesis.

\subsection{Approaches}

The PLCA and NMF approaches to the audio source separation problem are very
popular. An early and highly cited work that applies NMF to polyphonic music
transcription is \cite{smaragdis2003non}. Since then many variations on this
approach have been proposed. A technique using smoothness based on spectral
difference and sparseness as regularization terms is presented in
\cite{virtanen2007monaural}. In \cite{vincent2008harmonic} vectors in the
resulting matrices are forced to be a linear combination of predefined ``basis
spectra'', chosen for their harmonic and perceptual properties.
\cite{bertin2010enforcing} explores the uses of different divergences for the
purposes of upmixing and noise removal.

\subsection{PLCA}

In this formulation, the spectrogram (defined in Section~\ref{sec:timefreqrep}),
being non-negative like a probability distribution, is considered as such
\[
    c|X(t,f)| = \mathrm{p} (t,f)
\]
where c is a constant so that the distribution integrate to 1. Explicitly,
we consider the probability that energy in the spectrogram lie in the vicinity
of time $t$ and frequency $f$. With the hope of retrieving the spectrograms of
the $P$ underlying sources, it is proposed
that the distribution is actually the distribution of $K$ random variables each
being chosen with probability $\mathrm{p}(Z=k)$. The pair of random variables
from component $k$, $T_{k}$ and $F_{k}$ are assumed independent, i.e.,
$\mathrm{p}(t,f|Z=k)=\mathrm{p}(t|Z=k)\mathrm{p}(f|Z=k)$. Each random variable, it is
hoped, describes a source ($K=P$) or a part of a source ($K>P$). In addition,
each of these underlying distributions has marginal distributions $\mathrm{p}(t
| Z=k)$ and $\mathrm{p}(f | Z=k)$. The marginal distributions and
$\mathrm{p}(Z=k)$ can be estimated using the expectation maximization
algorithm
with the following update rules for the $l$th iteration of the
algorithm \cite{smaragdis2006probabilistic}
\[
    \mathrm{p}_{l+1}(Z=k | t, f)
    =
    \frac{\mathrm{p}_{l}(Z=k)\mathrm{p}_{l}(t|Z=k)\mathrm{p}_{l}(f|Z=k)}
    {\sum_{j=0}^{K-1}{\mathrm{p}_{l}(Z=j)\mathrm{p}_{l}(t|Z=j)\mathrm{p}_{l}(f|Z=j)}}
\]
\[
    \mathrm{p}_{l+1}(t|Z=k)
    =
    \frac{\sum_{f}\mathrm{p}(t,f)\mathrm{p}_{l+1}(Z=k|t,f)}
    {\sum_{s}\sum_{f}\mathrm{p}(s,f)\mathrm{p}_{l+1}(Z=k|s,f)}
\]
\[
    \mathrm{p}_{l+1}(f|Z=k)
    =
    \frac{\sum_{t}\mathrm{p}(t,f)\mathrm{p}_{l+1}(Z=k|t,f)}
    {\sum_{t}\sum_{g}\mathrm{p}(t,g)\mathrm{p}_{l+1}(Z=k|t,g)}
\]
\[
    \mathrm{p}_{l+1}(Z=k)
    \frac{\sum_{t}\sum_{f}\mathrm{p}(t,f)\mathrm{p}_{l+1}(Z=k|t,f)}
    {\sum_{j=0}^{K-1}\sum_{t}\sum_{f}\mathrm{p}(t,f)\mathrm{p}_{l+1}(Z=j|t,f)}
\]
After convergence, the marginal distribution $\mathrm{p}_{l^{\ast}}(t|Z=k)$
gives the distribution of energy of the $k$th component over time. Similarly, 
the marginal distribution $\mathrm{p}_{l^{\ast}}(f|Z=k)$
gives the distribution of energy of the $k$th component over frequency. Once the
set of components $\{ \tilde{k} \}$ belonging to the $p$th source has been
determined, we can synthesize the spectrogram of this source as
\[
    |X_{p}(t,f)| = \frac{1}{c}
    \sum_{j \in
    \{\tilde{k}\}}\mathrm{p}_{l^{\ast}}(t,f|Z=j)\mathrm{p}_{l^{\ast}}(Z=j)
\]
PLCA can be extended by the use of ``kernel distributions'' that allow the
specification of marginal distributions with both time and frequency extent, and
``entropic priors'' that encourage sparsity in the resulting marginal
distributions \cite{shashanka2008probabilistic}.

\subsection{NMF}

Instead of considering $|X(t,f)|$ as a probability distribution, we
consider it at discrete frequencies $mc_{f}$ and times $nc_{t}$ with $m,n \in
\mathbb{N}$, the entry at the $m$th row and $n$th column of matrix
$V_{m,n}=|X(nc_{t},mc_{f})|$ with non-negative entries. We seek an
approximate factorization of $\boldsymbol{V} \in \mathbb{R}^{M \times N}_{+}$
into matrices $\boldsymbol{W} \in \mathbb{R}^{M \times K}_{+}$ and
$\boldsymbol{H} \in \mathbb{R}^{K \times N}_{+}$ such that
\begin{equation}
    \boldsymbol{V} \approx \boldsymbol{W}\boldsymbol{H}
    \label{eq:VaprxWH}
\end{equation}
This can be done by solving the program
\[
    \min \mathcal{D}(\boldsymbol{V},\boldsymbol{W}\boldsymbol{H})
\]
subject to
\[
    \boldsymbol{V} \geq \boldsymbol{0}
\]
\[
    \boldsymbol{W} \geq \boldsymbol{0}
\]
\[
    \boldsymbol{H} \geq \boldsymbol{0}
\]
The particular choice of function $\mathcal(D)$ that measures divergence leads
to different update equations in the iterative procedure for finding
$\boldsymbol{W}$ and $\boldsymbol{H}$.

\subsubsection{The Kullback-Leibler divergence \cite{lee2001algorithms}}

The \textit{Kullback-Leibler} divergence function for measuring the divergence
between two matrices $\boldsymbol{X}$ and $\boldsymbol{Y}$ is
\[
    \mathcal{D}_{\text{KL}}(\boldsymbol{X},\boldsymbol{Y}) =
    \sum_{m=0}^{M-1}\sum_{n=0}^{N-1} X_{m,n}\log(Y_{m,n})-X_{m,n}+Y_{m,n}
\]
and can be minimzed using the following update equations for the $l$th iteration%
\footnote{It can be shown that these update equations are equivalent to those for PLCA 
\cite{shashanka2008probabilistic}.}
\[
    H_{a,b}^{l+1} =
    H_{a,b}^{l} \frac{\sum_{j=0}^{M-1}W_{j,a}^{l}V_{j,b}^{l} / (W^{l}H^{l})_{j,m}}
    {\sum_{j=0}^{M-1}W_{j,a}^{l}}
    W_{a,b}^{l+1} =
    W_{a,b}^{l} \frac{\sum_{j=0}^{N-1}H_{b,j}^{l+1}V_{a,j}^{l} / (W^{l}H^{l+1})_{a,j}}
    {\sum_{j=0}^{N-1}H_{b,j}^{l+1}}
\]

\subsubsection{The Itakura-Saito divergence \cite{fevotte2009nonnegative}}

Another divergence popular for factorizing spectrograms is the
\textit{Itakura-Saito} divergence 
\[
    \mathcal{D}_{\text{IS}}(\boldsymbol{X},\boldsymbol{Y}) =
    \sum_{m=0}^{M-1}\sum_{n=0}^{N-1} \frac{X_{m,n}}{Y_{m,n}}
    - \log \left(\frac{X_{m,n}}{Y_{m,n}}\right) -1
\]
This divergence is scale-invariant, meaning that
$\mathcal{D}_{\text{IS}}(c\boldsymbol{X},c\boldsymbol{Y})=\mathcal{D}_{\text{IS}}(\boldsymbol{X},\boldsymbol{Y})$,
which makes it well suited for audio signals which have a large dynamic range.
Put another way, divergences involving large values in $\boldsymbol{V}$ and
$\boldsymbol{W}\boldsymbol{H}$ will be weighted similarly to divergences
involving small values, which is not the case with the Kulback-Leibler
divergence.  The Itakura-Saito divergence is minimized through the following
update equations
\[
    \boldsymbol{H}^{l+1}
    =
    \boldsymbol{H}^{l}.
    \frac{\boldsymbol{W}^{lT}((\boldsymbol{W}^{l}\boldsymbol{H}^{l})^{.-2}.\boldsymbol{V}^{l})}
    {\boldsymbol{W}^{lT}(\boldsymbol{W}^{l}\boldsymbol{H}^{l})^{.-1}}
\]
\[
    \boldsymbol{W}^{l+1}
    =
    \boldsymbol{W}^{l}.
    \frac{((\boldsymbol{W}^{l}\boldsymbol{H}^{l+1})^{.-2}.\boldsymbol{V}^{l})\boldsymbol{H}^{l+1T}}
    {(\boldsymbol{W}^{l}\boldsymbol{H}^{l+1})^{.-1}\boldsymbol{H}^{l+1T}}
\]
Once convergence has been obtained the $k$th column of matrix $\boldsymbol{W}$ will contain
values representing the level of activation of the $k$th component at the
frequency corresponding to the row index and the $k$th row of $\boldsymbol{H}$ the level of
activation of the $k$th component at the time corresponding to the column index.
If the set of components $\{ \tilde{k} \}$ belonging to the $p$th source has
been determined, we can synthesize the spectrogram of this source as
\[
    |X_{p}(nc_{t},mc_{f})| =
    \sum_{j \in \{\tilde{k}\}}W_{:,j}H_{j,:}
\]
 
\subsection{Synthesis of factorized spectrograms}

Synthesizing the original signal is less straightforward as the phase
information contained in the STFT was discarded to obtain a non-negative
spectrogram. We can simply use the
original phases of the STFT used to compute the spectrum with the new magnitude
information from $|X_{p}(t,f)|$ but the resulting signal may have artifacts due to
the phase information of unwanted sources that remains in the STFT. A technique
to lessen these artifacts using constrained Wiener filtering has been proposed in
\cite{le2013consistent}. One may also choose to invert the spectrogram without
any phase information by using an algorithm that iteratively reconstructs the
phase part of the STFT while minimizing the error
between the spectrogram of the reconstructed signal and its original power
spectrum, starting from an initial guess \cite{griffin1984signal}. Each
iteration requires transforming the signal to its spectrogram and then back to
a time-domain signal, requiring considerable computational effort.

\subsection{Extensions and shortcomings}

As with PLCA, certain extensions can be integrated into NMF to encourage
particular solutions. For example, to promote sparseness in the resulting
matrices, i.e., to encourage that fewer entries be non-zero, one can add the
regularization term
\[
    \alpha\sum_{m=0}^{M-1}\sum_{k=0}^{K-1} W_{m,k}^{2}
    +
    \beta\sum_{k=0}^{K-1}\sum_{n=0}^{N-1} H_{k,n}^{2}
\]
to the divergence to penalize matricies with large entries.$\alpha$ and $\beta$
are terms that control the influence of this regularization. A variety of
regularization terms are possible \cite[ch.~3]{cichocki2009nonnegative}.

Equation~\ref{eq:VaprxWH} can be seen as the sum
\[
    V
    \approx
    \sum_{k=-0}^{K-1}\boldsymbol{w}_{:,k}\otimes\boldsymbol{h}_{l,:}
\]
i.e., the sum of all the outer products between columns of $\boldsymbol{W}$ and
rows of $\boldsymbol{H}$. From this perspective, we can see the columns of
$\boldsymbol{W}$ as a collection of $K$ spectral ``templates'' and the rows of
$\boldsymbol{H}$ as their time-varying gains. What this means is, sounds
exhibiting frequency-modulation require a large number of columns in
$\boldsymbol{W}$. This large number of columns makes the organizing of
templates into sources a difficult task.

\section{An approach using amplitude- and frequency-modulation
\label{sec:amfmapproach}}

Perceptual studies have shown that sounds modulated synchronously in amplitude
or frequency are heard as one sound, whereas asynchronously modulated sounds are
heard as distinct \cite{mcadams1989segregation} \cite{marin1991segregation}.
Here we define the modulation of parameters $\theta_i$ and $\theta_j$ as being
synchronous if they are given as functions of time, $\theta_i=f_i(t)$ and
$\theta_j=f_j(t)$ and there is an affine transform $\mathscr{A}$ such that
$\mathscr{A}\{f_i\}(t) \approx A f_j(t) + B$ where $A$ and $B$ are constants
that do not vary with time (at least for the time that we observe the signal).
If we can accurately measure these parameters and they are typical of the sounds
we are trying to separate, then we can design techniques to reliably separate
these sounds from acoustic mixtures. This involves picking those parameters
classified as belonging to the same sound, discarding the rest, and
resynthesizing from these parameters. The task of audio source separation
therefore comprises the following tasks:

\begin{itemize}
    \item
        Decide on a signal model for the sound of interest, with parameters that
        can be estimated and that are similar for similar sounds. We have chosen
        the additive sinusoidal model with a higher order polynomial description
        of amplitude and phase.
    \item
        Locate regions in the signal where these signals are thought to be
        present using a peak-picking technique. Estimate the signal parameters
        at these locations. Here we use the Distribution Derivative Method
        \cite{betser2009sinusoidal} to
        estimate these parameters.
    \item
        Use these measurements as input to a partial tracking algorithm. We
        compare the effectiveness of the original peak matching procedure of
        McAulay and Quatieri \cite{mcaulay1986speech} and a new linear
        programming formulation of the problem.
    \item
        Classify the partials and group them as sets of parameters coming from
        the same source: the sound of interest. The classification is carried
        out on the frequency- and amplitude-modulation parameters. Principal
        components analysis is used to preprocess the data before
        classification.
    \item
        Choose a group of parameters (partials) and synthesize the separated
        signal from them. We compare the quality of synthesis for three models.
        The first assumes constant amplitude and linear phase at the analysis
        step resulting in linear amplitude and cubic phase at the synthesis step
        \cite{mcaulay1986speech}. The second assumes quadratic amplitude and
        phase at the analysis step but constrains the amplitude to be cubic at
        the synthesis step. The final model assumes quadratic amplitude and
        phase at the analysis step resulting in a quartic model for phase and
        amplitude at the synthesis step.
\end{itemize}

It should be noted that the strategy for source separation is similar to that
proposed in \cite{creager2016musicalsource}. The work here differs in many
respects. We have chosen to use solely the additive sinusoidal model as a
model of the signals considered. Furthermore, in addition to
frequency-modulation, we incorporate amplitude-modulation to aid in the source
separation. Chapter~\ref{chap:decaysep} uses only the amplitude-modulation to
classify partials into sources. This is similar to the strategy explored in
\cite{li2009monaural}, but does not use a prior estimation of the fundamental
frequencies of the sources.
