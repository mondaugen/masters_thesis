\chapter{Introduction \label{chap:intro}}

\section{Motivation}

This thesis was written in the information age where digital signals can be
produced easily and are produced in great volumes. As stated in the introduction
of \cite{hayes2009statistical}, signals are the means by which information is
transmitted. In the past, producing a digital signal was costly and required
specialized equipment, motivating the user of the equipment to carefully plan
the process that was to be documented by encoding the measurements into the
signal. Now these tools are widely available and accessible to everyone,
increasing both the variance in quality, but also the potency of information.
For this reason, new signal processing techniques require ways of removing
extraneous information, that is, data that have meaning and structure, but that
are not pertinent to the information of interest. In this thesis, a producer of
information is a \textit{source}, and we have many sources transmitting
information in a single signal. 

Source separation is a difficult problem because it involves simultaneously
estimating characteristics of the sources while separating them: for improved
estimation, interference from other sources should be minimized; in order to
remove interfering sources, their characteristics must be known. For the
estimation problem, we must resort to using prior information: we assume we
know the structure of the sources and can quantify in some way their
characteristics, penalizing characterizations estimated by our system that do
not match presumptions. For the separation problem, we often must resort to
suboptimal solutions. These solutions may be adequate to aid a human in manual
refinement of the sources, or serve as input to another technique.

\section{Applications}

Applications of source separation exist in a variety of disciplines and entire
conferences are dedicated to the subject (see, for example,
\cite{zarzoso2010latent}).  Here we will only consider applications pertinent to
audio, acoustics and music. One of the most popular applications of audio source
separation is for automated music transcription (see e.g.,
\cite{bertin2010enforcing}). Having access to both a representation of the
musical score and its constituent sounds would be very convenient for composers
and sound engineers. Those interested in isolating individual voices in a
recording of multiple speakers (for honourable or dishonourable purposes) would
benefit from audio source separation --- \cite{mysore2012non} discusses a
strategy using characterizations of language to aid in the separation. There are
no doubt many more applications of source separation in the field of audio
signal processing.

\section{Organization}

The general strategy explored in this thesis is an iterative process with four
distinct steps.
\begin{enumerate*}[label=(\arabic*),itemjoin={{. }}]
\item a model is chosen of the signals of interest
\item realisations of this model are
identified in the measurement signal
\item once these have been identified, the parameters
of the realisations are estimated
\item the estimations are used to classify these
realisations as one of a smaller set of higher level objects.
\end{enumerate*}
The structure of these objects is used to inform the selection of the new model,
whose parameters are then estimated, etc.; the process can repeated to build
up successively higher level models.

This thesis is structured according to these steps and is as follows.
Chapter~\ref{chap:method} discusses previous approaches to audio source
separation and introduces the method adopted here. The following,
Chapter~\ref{chap:sigmod}, describes the signal model chosen to describe musical
signals --- the additive sinusoidal model with polynomial log-amplitude and
phase --- and describes a technique for estimating the parameters of models of
arbitrary order. We introduce a new analysis window to have more control over the
estimation process. Techniques to identify these models in signals are discussed in
Chapter~\ref{chap:partialtracking}, where a classical technique of partial
tracking is compared to a new linear programming formulation.
Chapter~\ref{chap:exphsmodel} shows how the separated sources can be synthesized
from the estimated model parameters using the additional information provided by
the higher-order polynomial model. Finally, two experiments are carried out that
demonstrate the use of amplitude- and frequency-modulation to classify sources.
The first, in Chapter~\ref{chap:amfmsep} is on synthetic data and the second in
Chapter~\ref{chap:decaysep} on a recording of percussion and plucked string
instruments. It is in these latter chapters where classification is performed
and its adaptation to the particular audio source separation problem is
discussed. The Appendices~\ref{chap:pca}~through~\ref{chap:normaldist} explain
elements of these classification techniques.

\section{Notation}

\subsection{Vectors and matrices}

While scalars are typeset normally --- $x$ is an example of a scalar --- vectors
and matrices are typeset in a boldface font, with matrices written with a
capital letter, e.g., $\boldsymbol{x}$ is a vector and $\boldsymbol{X}$ a
matrix. If a number is written instead of a symbol, we mean a vector all of that
number, e.g., $\boldsymbol{1}$ is the vector of all $1$s, $\boldsymbol{0}$ the
vector of all $0$s. The $i$th entry of a vector $\boldsymbol{x}$ is written
$x_{i}$ and the entry in the $i$th row and $j$th column of a matrix $X$ is
written $X_{i,j}$.  Both are scalars and therefore typeset normally. Sometimes
we might find it convenient to extract a column vector or row vector from the
matrix $\boldsymbol{X}$. We write $\boldsymbol{x}_{i,:}$ to extract all columns
from the $i$th row and $\boldsymbol{x}_{:,j}$ to extract all rows from the
$j$th column. These are the $i$th row vector and $j$th column vector
respectively. The orientation of a vector will be clear from the context, but in
general $\boldsymbol{x}$ is a column vector while $\boldsymbol{y}_{i,:}$ and
$\boldsymbol{x}^{T}$ are row vectors.

\subsection{Operators}

\subsubsection{Inner product}

We will be dealing with objects in vector spaces. The operator $\left\langle
x, y \right\rangle$ takes two objects in a vector space $V$, $x,y \in V$ and maps
them to an element $k \in \mathbb{K}$ of a field $\mathbb{K}$.
For this thesis, the field will always be the field of real numbers
$\mathbb{R}$ or complex numbers $\mathbb{C}$. The vector space can be the set of
vectors of $N$ elements in $\mathbb{R}^{N}$ or $\mathbb{C}^{N}$, in which case
the inner product is defined, for $\boldsymbol{x},\boldsymbol{y} \in
\mathbb{K}^{N}$, $k \in \mathbb{K}$
\[
    \left\langle  \boldsymbol{x}, \boldsymbol{y} \right\rangle =
\boldsymbol{x}^{T} \boldsymbol{y} = k
\]
The inner product is also defined on
the vector space of functions $\Phi$
mapping from a set $S$ to a field $\mathbb{K}$, $\Phi : \forall f \text{ s.t. } f(s) = k, s \in S,k \in
\mathbb{K} $ in which case the inner product on $g,f \in \Phi$ is
defined as
\[
    \left\langle  g, f \right\rangle =
\int_{-\infty}^{\infty} g(x) \overline{f(x)} dx
\]
and $\overline{a}$ gives the complex conjugate of $a$.

\subsubsection{General outer operators}

The outer operator $\cdotp \otimes_{\mathcal{O}} \cdotp$ will only be defined for
vectors in this thesis. It operates on the two vectors $\boldsymbol{x},\boldsymbol{y} \in
\mathbb{K}^{N}$ and is defined as
\[
    \boldsymbol{x} \otimes_{\mathcal{O}} \boldsymbol{y} = \boldsymbol{W}
\] where the $i$th row and $j$th column of $\boldsymbol{W}$ are
\[
    w_{i,j} = \mathcal{O} (x_{i},y_{j})
\]
Canonically, the operator $\mathcal{O}$ is multiplication in which case
\[
    \boldsymbol{x} \otimes_{\times} \boldsymbol{y} = \boldsymbol{W}
\] where the $i$th row and $j$th column of $W$ are
\[
    W_{i,j} = x_{i} y_{j}
\]
This outer product is also known as the \textit{Kronecker product}, and we will
omit the operator subscript when that is the case, i.e., we will simply write $\otimes$.  As stated
above, however, $\mathcal{O}$ can be defined arbitrarily as any function taking
two inputs a returning a single output.

\subsubsection{Point-wise operators}

If an operator on matrices $\circ$ is written with a period preceding it, i.e.,
$.\circ$ it
means perform that operation on each element individually. Some examples follow.

For matrix $\boldsymbol{X} \in \mathbb{K}^{M,N}$ and $p \in \mathbb{K}$
\[
    \boldsymbol{X}^{.p} = \boldsymbol{W}
\] where
\[
    W_{i,j}=X_{i,j}^{p}
\]
For matrices $\boldsymbol{X},\boldsymbol{Y} \in \mathbb{K}^{M,N}$
\[
    \boldsymbol{X}.\boldsymbol{Y} = \boldsymbol{W}
\] where
\[
    W_{i,j}=X_{i,j}Y_{i,j}
\]
(contrast these with canonical matrix multiplication).

\subsection{Random variables}

Many authors denote random variables with a normally typeset uppercase letter.
We will use this convention only when convenient, but will always state
explicitly that a certain variable is random. We distinguish between discrete and
random variables in our notation.

\subsubsection{Discrete random variables}

If a random variable $X$ can only take on values in a discrete set, we say that this
random variable is discrete-valued. Formally a discrete set $\Gamma$ of size $N$
is one for which there exists an isomorphism $\mathscr{I}$ that maps $\Gamma$ on
to the subset of the integers $[1 \dotsc, N]$. The probability that $X$ takes on
the value $x$ is written $\mathrm{p}(X=x)$ for discrete random variables.

\subsubsection{Continuous random variables}

If a random variable $X$ can take on values in a set $\Gamma$ isomorphic to
$\mathbb{R}$ we say this random variable is continuous-valued. The probability
that $X$ takes on the value $x$ is written $\mathrm{p}(x)$ for continuous random
variables.

\subsection{Complex numbers}

A complex number $z \in \mathbb{C}$ can be described in Cartesian notation as
\[
    z = a + jb, a,b \in \mathbb{R}
\]
or in polar notation as
\[
    z = \alpha \exp(j\omega), \alpha,\omega \in \mathbb{R}
\]
where $j = \sqrt{-1}$. $j$ is also often used to denote an index variable. It
will be clear from the context when the imaginary number is meant and when the
index.

\subsection{Logarithms}

The logarithm base-$e$\footnote{$e$ is Euler's constant.} of $x$ is written
$\log(x)$. The logarithm of any other base $b$ will be denoted as such:
$\log_{b}(x)$.

\subsection{Ultimate values}

This thesis presents a number of iterative algorithms whose steps will 
be counted using an index $l$ and whose solutions will take on the values
$x_{l}$. We use the
$\ast$ notation to refer to these values at the final iterates: the index of the
final iteration is written\footnote{Arbitrary letters can be used.} $l^{\ast}$ and its value $x_{l^{\ast}}=x^{\ast}$.
