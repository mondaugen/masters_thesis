\chapter{Principal components analysis (PCA)\label{chap:pca}}

\section{Motivation}

If data-points consist of more than two dimensions (say $p$), it becomes
burdensome to try and find the single best or two best dimensions on which to
examine for grouping. If we consider variables on each of the dimensions that
take on the data-point's corresponding values, we are interested in the
variables that capture most of the data-points's variance. It turns out we can
determine a linear transformation of our original dataset giving $p$ variables
and their $p$ variances such that the resulting variable with the highest
variance will have the maximum variance achievable, under some constraints that
will be explained shortly. 

\section{Computation of principal components}

The following development is based on \cite{jolliffe2002principal}. Say we have
a set $\left\{ \boldsymbol{x} \right\}$ of data-points and their covariance
matrix $\boldsymbol{S}$. A linear function of $\boldsymbol{x}$,
$f_1(\boldsymbol{x})=\boldsymbol{a}_{1}^{T}\boldsymbol{x}$ has variance
$\sigma_{\boldsymbol{a}_{1}^{T}\boldsymbol{x}}=\boldsymbol{a}_{1}^{T}\boldsymbol{S}\boldsymbol{a}_{1}$.
Therefore, we desire a vector $a$ that maximizes
$\sigma_{\boldsymbol{a}_{1}^{T}\boldsymbol{x}}$. We can find this via the program
\[
        \max \boldsymbol{a}_{1}^{T}\boldsymbol{S}\boldsymbol{a}_{1}
\]
subject to
\[
    \boldsymbol{a}_{1}^{T}\boldsymbol{S}\boldsymbol{a}_{1}=1
\]
(to obtain a bounded solution).

The resulting function of $\boldsymbol{x}$,
$f_1(\boldsymbol{x})=\boldsymbol{a}_{1}^{\ast T}\boldsymbol{x}$ is called the first
\textit{principal component}. The second principal component
$f_2(\boldsymbol{x})=\boldsymbol{a}_{2}^{\ast T}\boldsymbol{x}$ is found similarly
to the first, except with the additional constraint that it be uncorrelated
(orthogonal) to the first component, i.e.,
$\boldsymbol{a}_{2}^{\ast T}\boldsymbol{a}_{1}=0$, and the third is found by
requiring orthogonality with the first two principal components, etc.

The principal components now allow us to examine for grouping more easily as the
total variance of the dataset has been captured in the first few principal component
variables. These transformed data-points can now be classified using a
classification algorithm --- see Appendix~\ref{chap:gmm} for the classification
algorithm used for the experiments in this thesis.
